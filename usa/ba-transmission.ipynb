{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import requests\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USA Balancing Authority Interchnage Capacity\n",
    "This notebook estimates tranmsission capacity between balancing authorities in the USA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url: str, destination: str):\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        with open(destination, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"File downloaded successfully to {destination}\")\n",
    "    else:\n",
    "        print(f\"Failed to download file. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_exists(file_path: str):\n",
    "    path = Path(file_path)\n",
    "    return path.is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory(directory: str):\n",
    "    d = Path(directory)\n",
    "    if not d.exists():\n",
    "        d.mkdir(parents=True)\n",
    "        print(f\"Directory '{d}' created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract flow data from EIA\n",
    "Downloaded 6-month files on interchanges for 2019-2023 from [EIA930](https://www.eia.gov/electricity/gridmonitor/dashboard/electric_overview/US48/US48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Sometimes the download on this gets stuck and idk why. \n",
    "# If needed, just try rerunning a couple times. It should only take ~10sec per file download\n",
    "\n",
    "files = [f\"{y}_{m}\" for y in range(2019,2024) for m in [\"Jan_Jun\", \"Jul_Dec\"]]\n",
    "\n",
    "create_directory(\"flows\")\n",
    "\n",
    "base_url = \"https://www.eia.gov/electricity/gridmonitor/sixMonthFiles/EIA930_INTERCHANGE\"\n",
    "for f in files: \n",
    "    if not file_exists(f\"flows/{f}.csv\"):\n",
    "        url = f\"{base_url}_{f}.csv\"\n",
    "        print(url)\n",
    "        download_file(url, f\"flows/{f}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "Note, this dataframe will load about 1GB of data into memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balancing Authority</th>\n",
       "      <th>Data Date</th>\n",
       "      <th>Hour Number</th>\n",
       "      <th>Directly Interconnected Balancing Authority</th>\n",
       "      <th>Interchange (MW)</th>\n",
       "      <th>Local Time at End of Hour</th>\n",
       "      <th>UTC Time at End of Hour</th>\n",
       "      <th>Region</th>\n",
       "      <th>DIBA_Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AEC</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>1</td>\n",
       "      <td>MISO</td>\n",
       "      <td>28.0</td>\n",
       "      <td>01/01/2019 1:00:00 AM</td>\n",
       "      <td>01/01/2019 7:00:00 AM</td>\n",
       "      <td>SE</td>\n",
       "      <td>MIDW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AEC</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>1</td>\n",
       "      <td>SOCO</td>\n",
       "      <td>25.0</td>\n",
       "      <td>01/01/2019 1:00:00 AM</td>\n",
       "      <td>01/01/2019 7:00:00 AM</td>\n",
       "      <td>SE</td>\n",
       "      <td>SE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AEC</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>2</td>\n",
       "      <td>MISO</td>\n",
       "      <td>33.0</td>\n",
       "      <td>01/01/2019 2:00:00 AM</td>\n",
       "      <td>01/01/2019 8:00:00 AM</td>\n",
       "      <td>SE</td>\n",
       "      <td>MIDW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEC</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>2</td>\n",
       "      <td>SOCO</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>01/01/2019 2:00:00 AM</td>\n",
       "      <td>01/01/2019 8:00:00 AM</td>\n",
       "      <td>SE</td>\n",
       "      <td>SE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AEC</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>3</td>\n",
       "      <td>MISO</td>\n",
       "      <td>34.0</td>\n",
       "      <td>01/01/2019 3:00:00 AM</td>\n",
       "      <td>01/01/2019 9:00:00 AM</td>\n",
       "      <td>SE</td>\n",
       "      <td>MIDW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Balancing Authority   Data Date  Hour Number  \\\n",
       "0                 AEC  01/01/2019            1   \n",
       "1                 AEC  01/01/2019            1   \n",
       "2                 AEC  01/01/2019            2   \n",
       "3                 AEC  01/01/2019            2   \n",
       "4                 AEC  01/01/2019            3   \n",
       "\n",
       "  Directly Interconnected Balancing Authority  Interchange (MW)  \\\n",
       "0                                        MISO              28.0   \n",
       "1                                        SOCO              25.0   \n",
       "2                                        MISO              33.0   \n",
       "3                                        SOCO              -1.0   \n",
       "4                                        MISO              34.0   \n",
       "\n",
       "  Local Time at End of Hour UTC Time at End of Hour Region DIBA_Region  \n",
       "0     01/01/2019 1:00:00 AM   01/01/2019 7:00:00 AM     SE        MIDW  \n",
       "1     01/01/2019 1:00:00 AM   01/01/2019 7:00:00 AM     SE          SE  \n",
       "2     01/01/2019 2:00:00 AM   01/01/2019 8:00:00 AM     SE        MIDW  \n",
       "3     01/01/2019 2:00:00 AM   01/01/2019 8:00:00 AM     SE          SE  \n",
       "4     01/01/2019 3:00:00 AM   01/01/2019 9:00:00 AM     SE        MIDW  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtypes = {\n",
    "    \"Balancing Authority\":str,\n",
    "    \"Data Date\":str,\n",
    "    \"Hour Number\":int,\n",
    "    \"Directly Interconnected Balancing Authority\":str,\n",
    "    \"Interchange (MW)\":str,\n",
    "    \"Local Time at End of Hour\":str,\n",
    "    \"UTC Time at End of Hour\":str,\n",
    "    \"Region\":str,\n",
    "    \"DIBA_Region\":str\n",
    "}\n",
    "\n",
    "dfs = []\n",
    "for f in files:\n",
    "    df = pd.read_csv(f\"flows/{f}.csv\", dtype=dtypes)\n",
    "    df[\"Interchange (MW)\"] = df[\"Interchange (MW)\"].astype(str)\n",
    "    df[\"Interchange (MW)\"] = df[\"Interchange (MW)\"].str.replace(\",\",\"\")\n",
    "    df[\"Interchange (MW)\"] = df[\"Interchange (MW)\"].astype(float)\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Retired BAs \n",
    "Manually taken from the list of reporting entities provided here by the EIA [here](https://www.eia.gov/electricity/gridmonitor/about) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "retired = [\"AEC\", \"EEI\", \"GLHB\", \"GRMA\", \"NSB\", \"OVEC\", \"WAUE\", \"CFE\"]\n",
    "df = df[\n",
    "    (~df[\"Balancing Authority\"].isin(retired)) & \n",
    "    (~df[\"Directly Interconnected Balancing Authority\"].isin(retired)).dropna()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Data\n",
    "Get timeseries of formatted flows to/from each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tran = df.copy()\n",
    "tran[\"From_raw\"] = tran[\"Region\"].str.cat(tran[\"Balancing Authority\"], sep=\"-\")\n",
    "tran[\"To_raw\"] = tran[\"DIBA_Region\"].str.cat(tran[\"Directly Interconnected Balancing Authority\"], sep=\"-\")\n",
    "tran.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct for the negative flows \n",
    "# the data can be +/- for MISO->ASCI and ASCI->MISO \n",
    "# correct everything so all flows are positive by flipping BA flow paths \n",
    "tran[\"From\"] = tran.apply(lambda x: x[\"From_raw\"] if x[\"Interchange (MW)\"] >= 0 else x[\"To_raw\"], axis=1)\n",
    "tran[\"To\"] = tran.apply(lambda x: x[\"To_raw\"] if x[\"Interchange (MW)\"] >= 0 else x[\"From_raw\"], axis=1)\n",
    "tran[\"Capacity (MW)\"] = tran[\"Interchange (MW)\"].abs()\n",
    "tran.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran[\"time\"] = pd.to_datetime(tran[\"Local Time at End of Hour\"])\n",
    "tran = tran.set_index(\"time\")[[\"To\", \"From\", \"Capacity (MW)\"]]\n",
    "tran.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Max Flow Rates\n",
    "Get max flow values to/from each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows = tran.copy()\n",
    "flows[\"To-From\"] = flows[\"To\"].str.cat(flows[\"From\"], sep=\">\")\n",
    "flows[\"From-To\"] = flows[\"From\"].str.cat(flows[\"To\"], sep=\">\")\n",
    "flows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers\n",
    "clip anything outside of the 5-95 percentile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes 5-10min to run \n",
    "# https://stackoverflow.com/a/43093390\n",
    "max_flow = {}\n",
    "for flow in flows[\"To-From\"].unique():\n",
    "    f = flows[flows[\"To-From\"] == flow]\n",
    "    q_low = f[\"Capacity (MW)\"].quantile(0.05)\n",
    "    q_hi  = f[\"Capacity (MW)\"].quantile(0.95)\n",
    "    f_clipped = f[(f[\"Capacity (MW)\"] < q_hi) & (f[\"Capacity (MW)\"] > q_low)]\n",
    "    if f_clipped.empty:\n",
    "        max_flow[flow] = 0\n",
    "    else:\n",
    "        max_flow[flow] = f_clipped[\"Capacity (MW)\"].max()\n",
    "for flow in flows[\"From-To\"].unique():\n",
    "    f = flows[flows[\"From-To\"] == flow]\n",
    "    q_low = f[\"Capacity (MW)\"].quantile(0.05)\n",
    "    q_hi  = f[\"Capacity (MW)\"].quantile(0.95)\n",
    "    f_clipped = f[(f[\"Capacity (MW)\"] < q_hi) & (f[\"Capacity (MW)\"] > q_low)]\n",
    "    if f_clipped.empty:\n",
    "        max_flow[flow] = 0\n",
    "    else:\n",
    "        max_flow[flow] = f_clipped[\"Capacity (MW)\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_paths = set(flows[\"To-From\"].unique()).union(flows[\"From-To\"].unique())\n",
    "\n",
    "capacity = []\n",
    "for ba_path in ba_paths:\n",
    "    ba_1 = ba_path.split(\">\")[0]\n",
    "    ba_2 = ba_path.split(\">\")[1]\n",
    "    try:\n",
    "        max_flow_to_from = max_flow[f\"{ba_1}>{ba_2}\"]\n",
    "    except KeyError:\n",
    "        max_flow_to_from = 0\n",
    "    try:\n",
    "        max_flow_from_to = max_flow[f\"{ba_2}>{ba_1}\"]\n",
    "    except KeyError:\n",
    "        max_flow_from_to = 0\n",
    "        \n",
    "    max_flows = sorted([max_flow_to_from, max_flow_from_to])\n",
    "    \n",
    "    diff = abs((max_flows[0] - max_flows[1]) / max_flows[1])\n",
    "    \n",
    "    if diff < 0.15:\n",
    "        max_flow_bidrectional = max(max_flow_to_from, max_flow_from_to)\n",
    "        capacity.append([\n",
    "            ba_1, ba_2, max_flow_bidrectional, max_flow_bidrectional * (-1)\n",
    "        ])\n",
    "    else:\n",
    "        capacity.append([\n",
    "            ba_1, ba_2, max_flow_to_from, max_flow_from_to * (-1)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_max_flow = pd.DataFrame(capacity, columns=[\"BA_From\", \"BA_To\", \"Cap (MW) +\", \"Cap (MW) -\"])\n",
    "df_max_flow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format data for database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_ba_map = pd.read_csv(\"./ba-mapper.csv\")\n",
    "region_ba_map.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_2_code = region_ba_map.set_index(\"region-ba\").to_dict()[\"code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_max_flow_formatted = df_max_flow.copy()\n",
    "df_max_flow_formatted[\"BA_From\"] = df_max_flow_formatted[\"BA_From\"].map(region_2_code)\n",
    "df_max_flow_formatted[\"BA_To\"] = df_max_flow_formatted[\"BA_To\"].map(region_2_code)\n",
    "df_max_flow_formatted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for _, row in df_max_flow_formatted.iterrows(): # super inefficient :(\n",
    "    order = sorted([row[\"BA_From\"], row[\"BA_To\"]])\n",
    "    if row[\"BA_From\"] == order[0]:\n",
    "        data.append([\n",
    "            f\"TRN{row['BA_From']}{row['BA_To']}\",\n",
    "            row[\"BA_From\"],\n",
    "            row[\"BA_To\"],\n",
    "            row[\"Cap (MW) +\"],\n",
    "            row[\"Cap (MW) -\"],\n",
    "        ])\n",
    "    else:\n",
    "        data.append([\n",
    "            f\"TRN{row['BA_To']}{row['BA_From']}\",\n",
    "            row[\"BA_To\"],\n",
    "            row[\"BA_From\"],\n",
    "            row[\"Cap (MW) -\"] * (-1),\n",
    "            row[\"Cap (MW) +\"] * (-1),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame(data, columns=[\"TECHNOLOGY\", \"From\", \"To\", \"Cap (MW) +\", \"Cap (MW) -\"])\n",
    "final = final.drop_duplicates()\n",
    "final = final.sort_values(by=[\"TECHNOLOGY\"])\n",
    "final.to_csv(\"Transmission-Capacity.csv\", index=False)\n",
    "final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pypsa-usa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
